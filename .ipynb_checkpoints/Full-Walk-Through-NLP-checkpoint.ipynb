{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f216bb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re \n",
    "import string \n",
    "import nltk \n",
    "import warnings\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16599e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Tweets\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "# declare variables and query\n",
    "tweets_list = []\n",
    "tweet_count = 1000\n",
    "query = \"Biden since:2021-01-01 until:2022-11-13\" \n",
    "\n",
    "# use TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "    if i>tweet_count:\n",
    "        break\n",
    "    tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc31ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tweets\n",
    "\n",
    "def clean_string(a):\n",
    "    \n",
    "    # remove emoji's\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    a = emoji_pattern.sub(r'', a)\n",
    "\n",
    "    # remove @ symbols and hashtags\n",
    "    re_list = ['@[A-Za-z0â€“9_]+', '#']\n",
    "    combined_re = re.compile( '|'.join( re_list) )\n",
    "    a = re.sub(combined_re,'',a)\n",
    "\n",
    "    # remove urls from text\n",
    "    pattern = re.compile(r'(https?://)?(www\\.)?(\\w+\\.)?(\\w+)(\\.\\w+)(/.+)?')\n",
    "    a = re.sub(pattern,'',a)\n",
    "    output = a\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "# clean tweets with function we wrote above\n",
    "df = tweets_df\n",
    "for i in range(1001):\n",
    "    df['Text'][i] = clean_string(df.iloc[i]['Text'])\n",
    "    \n",
    "for i in range(5):\n",
    "    output = df.iloc[i]['Text']\n",
    "    print(output)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73342a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csvs just in case\n",
    "df.to_csv(r'C:\\Users\\maxma\\Downloads\\CS\\NLP\\Full Walk Through\\BidenTweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f6bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate word cloud\n",
    "\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "tk = WordPunctTokenizer()\n",
    "\n",
    "def tokenize_and_process(d):\n",
    "    \n",
    "    d = str(d)\n",
    "    lower_case = d.lower()\n",
    "    words = tk.tokenize(lower_case)\n",
    "    result_words = [x for x in words if len(x) > 2]\n",
    "    return (\" \".join(result_words)).strip()\n",
    "\n",
    "processed_tweets = []\n",
    "print ('Processsing and tokenizing tweets')\n",
    "for i in range(1000):\n",
    "    if i % 100 == 0:\n",
    "        print(\"Tweets {} of {} have been processed\".format(i, 1000))\n",
    "    processed_tweets.append(tokenize_and_process(df.Text[i]))\n",
    "    \n",
    "    \n",
    "string = pd.Series(processed_tweets).str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6ef926",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "custom_stopwords = ['biden','joe']\n",
    "stopwords.update(custom_stopwords)\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "wordcloud = WordCloud(width=1600, stopwords=stopwords,height=800,max_font_size=200,max_words=500,collocations=False, background_color='black').generate(string)\n",
    "plt.figure(figsize=(40,30))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83cca2d",
   "metadata": {},
   "source": [
    "#### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243618df",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers requests beautifulsoup4 pandas numpy\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import requests\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154e2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('nlptown/bert-base-multilingual-uncased-sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd985889",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode('I Love', return_tensors='pt')\n",
    "result = model(tokens)\n",
    "result.logits\n",
    "int(torch.argmax(result.logits))+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7706de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score(review):\n",
    "    tokens = tokenizer.encode(review, return_tensors='pt')\n",
    "    result = model(tokens)\n",
    "    return int(torch.argmax(result.logits))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d7ecb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.iloc[0]['Text']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2be62",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_score(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de758c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = df['Text'].apply(lambda x: sentiment_score(x[:512]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1f0ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = df['sentiment'].value_counts()\n",
    "y = [a[1],a[2],a[3],a[4],a[5]]\n",
    "x = [1,2,3,4,5]\n",
    "plt.bar(x,y)\n",
    "\n",
    "plt.xlabel(\"Joe Biden Tweets - Sentiment Score\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f240eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e7f624",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae46935f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
